tb <- table(logistic_model_ncf.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
weight_minority_class = sum(FS_Subset$FS_Status == "Food Secure")/sum(FS_Subset$FS_Status == "Food Insecure")
for(i in seq_len(NROW(FS_Subset))){
if(FS_Subset$FS_Status[i] == "Food Insecure"){
FS_Subset$Weight[i] = weight_minority_class
}
else
FS_Subset$Weight[i] = 1
}
FS_Subset$Weight <- as.numeric(FS_Subset$Weight)
summary(FS_Subset$Weight)
## Splitting again because train and test doesn't contain the weight column
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(FS_Subset), replace = TRUE, prob = c(0.6, 0.4))
train <- FS_Subset[sample, ]
test  <- FS_Subset[!sample, ]
logistic_weighted <- glm(FS_Status ~ Ethnicity +  Family_Size + Household_Income:SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = train,  weights = Weight, family = "binomial")
logistic_model2.prob <- predict(logistic_weighted, test, type = "response")
logistic_model2.pred = rep("Food Secure", dim(test)[1])
logistic_model2.pred[logistic_model2.prob > .5] = "Food Insecure"
tb <- table(logistic_model2.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
test$logistic_model2.prob <- logistic_model2.prob
roc_model2 <- roc(FS_Status ~ logistic_model2.prob, data = test)
plot(roc_model2)
auc(roc_model2)
train$logistic_model2_train.prob <- predict(logistic_weighted, train, type = "response")
# distribution of the prediction score grouped by known outcome
ggplot( train, aes( logistic_model2_train.prob, color = as.factor(FS_Status) ) ) +
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) +
scale_color_economist( name = "data", labels = c( "Food Secure", "Food Insecure" ) ) +
theme_economist()
data.balanced.ou <- ovun.sample(FS_Status~., data=train, p=0.5,  seed=1, method="under")$data
logistic_both <- glm(FS_Status ~ Ethnicity + Family_Size + Household_Income:SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = data.balanced.ou,   family = "binomial")
logistic_model3.prob <- predict(logistic_both, test, type = "response")
logistic_model3.pred = rep("Food Secure", dim(test)[1])
logistic_model3.pred[logistic_model3.prob > .5] = "Food Insecure"
tb <- table(logistic_model3.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
train$logistic_model3_train.prob <- predict(logistic_both, train, type = "response")
ggplot( train, aes( logistic_model3_train.prob, color = as.factor(FS_Status) ) ) +
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) +
scale_color_economist( name = "data", labels = c( "Food Secure", "Food Insecure" ) ) +
theme_economist()
knn_data <- FS_Subset
knn_data$Family_Size <- as.numeric(FS_Subset$Family_Size)
knn_data$Household_Income <- as.numeric(FS_Subset$Household_Income)
knn_data$SNAP <- as.numeric(FS_Subset$SNAP)
knn_data$Number_of_Jobs <- as.numeric(FS_Subset$Number_of_Jobs)
knn_data$Hours_on_Jobs <- as.numeric(FS_Subset$Hours_on_Jobs)
knn_data$Number_of_children <- as.numeric(FS_Subset$Number_of_children)
knn_data$FS_Status <- as.numeric(FS_Subset$FS_Status)
num_data <- select_if(knn_data, is.numeric)
num_data <- as.data.frame(num_data[-c(8)])
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 1, 3)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 2, 1)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 3, 2)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 2, 0)
str(num_data)
data_balanced_under <- as.data.frame(ovun.sample(FS_Status ~ ., data = num_data, method = "both", N = nrow(num_data), seed = 1)$data)
table(data_balanced_under$FS_Status)
num_data <- data_balanced_under
str(num_data)
scaledata <- as.data.frame(scale(num_data, center = TRUE, scale = TRUE))
str(scaledata)
set.seed(1000)
knn_sample <- sample(2, nrow(scaledata), replace=TRUE, prob=c(0.67, 0.33))
# X variables
knn_training <- scaledata[knn_sample==1, 1:6]
knn_test <- scaledata[knn_sample==2, 1:6]
# Y variable
knn.trainLabels <- num_data[knn_sample==1, 7]
knn.testLabels <- num_data[knn_sample==2, 7]
# Loading package
library(e1071)
library(caTools)
library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
library(class)
# create an empty dataframe to store the results from confusion matrices
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
kseq <- seq(1,15,2)
for (kval in kseq)
{
print( paste("k = ", kval) )
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=kval)
knn_crosst <- CrossTable(knn.testLabels, knn_pred, prop.chisq = FALSE)
knn_crosst
#
cm = confusionMatrix(knn_pred, reference = as.factor(knn.testLabels )) # from caret library
# print.confusionMatrix(cm)
#
cmaccu = cm$overall['Accuracy']
#print( paste("Total Accuracy = ", cmaccu ) )
# print("Other metrics : ")
# print(cm$byClass)
#
cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics
# cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
ResultDf = rbind(ResultDf, cmt)
print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
ResultDf = rbind(ResultDf, cmt)
xkabledply(ResultDf, "Total Accuracy Summary")
ggplot(ResultDf,aes(x = k, y = Total.Accuracy)) +
geom_line(color = "maroon", size = 1.5) +
geom_point(size = 3) +
labs(title = "Accuracy vs k")
library(class)
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=6)
knn_crosst <- gmodels::CrossTable(x = knn.testLabels, y = knn_pred, prop.chisq = FALSE)
kseq <- seq(3,15,2)
for (kval in kseq)
{
print( paste("k = ", kval) )
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=kval)
knn_crosst <- CrossTable(knn.testLabels, knn_pred, prop.chisq = FALSE)
knn_crosst
#
cm = confusionMatrix(knn_pred, reference = as.factor(knn.testLabels )) # from caret library
# print.confusionMatrix(cm)
#
cmaccu = cm$overall['Accuracy']
#print( paste("Total Accuracy = ", cmaccu ) )
# print("Other metrics : ")
# print(cm$byClass)
#
cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics
# cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
ResultDf = rbind(ResultDf, cmt)
print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
ResultDf = rbind(ResultDf, cmt)
xkabledply(ResultDf, "Total Accuracy Summary")
ggplot(ResultDf,aes(x = k, y = Total.Accuracy)) +
geom_line(color = "maroon", size = 1.5) +
geom_point(size = 3) +
labs(title = "Accuracy vs k")
kseq <- seq(3,15,2)
for (kval in kseq)
{
print( paste("k = ", kval) )
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=kval)
knn_crosst <- CrossTable(knn.testLabels, knn_pred, prop.chisq = FALSE)
knn_crosst
#
cm = confusionMatrix(knn_pred, reference = as.factor(knn.testLabels )) # from caret library
# print.confusionMatrix(cm)
#
cmaccu = cm$overall['Accuracy']
#print( paste("Total Accuracy = ", cmaccu ) )
# print("Other metrics : ")
# print(cm$byClass)
#
cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics
# cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
ResultDf = rbind(ResultDf, cmt)
print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
library(dplyr)
library(ezids)
library(ggplot2)
library(epiR)
library(pROC)
library(smotefamily)
library(ROSE)
library(ggthemes)
library(caret)
library(car)
library(ROSE)
Food_Sec <- data.frame(read.csv("dec21pub.csv"))
FS_Subset <- subset(Food_Sec, HRINTSTA == 001 & HRSUPINT == 001 & HRFS12MD != -9)
FS_Subset <- subset(FS_Subset, select = c(	"GESTFIPS",	"HRNUMHOU",	"HEFAMINC",	"HESP1",	"PTDTRACE",	"PRCITSHP",	"PEMJNUM",	"PEHRUSL1",	"PEEDUCA", "PRNMCHLD" , "HRFS12MD"))
FS_Subset <- FS_Subset %>% rename("States" = "GESTFIPS", "Family_Size" = "HRNUMHOU",	"Household_Income" = "HEFAMINC",	"SNAP" = "HESP1",	"Ethnicity" =	"PTDTRACE", "Citizenship_status" = "PRCITSHP",	"Number_of_Jobs" = "PEMJNUM",	"Hours_on_Jobs" = "PEHRUSL1" , "Education_Level" = "PEEDUCA" , "Number_of_children" = "PRNMCHLD",  "FoodSecurity_score" = "HRFS12MD")
## Converting the all the columns to factors as they are all ordinal(except the Id, but since it's categorical i'm converting it into a factor too)
FS_Subset[] <- lapply( FS_Subset, factor)
str(FS_Subset)
levels(FS_Subset$'FoodSecurity_score') <- c( "High Food Security", "Marginal Food Security", "Low Food Security", "Very Low Food Security")
FS_Subset$FS_Status <- FS_Subset$FoodSecurity_score
levels(FS_Subset$FS_Status) <- c( "Food Secure", "Food Secure", "Food Insecure", "Food Insecure")
levels(FS_Subset$'Ethnicity') <- c('White only', 'Black only', 'American Indian, Alaskan native only', 'Asian Only', 'Hawaiian', 'White-black', 'White-AI', 'White-Asian', 'White-HP', 'Black-AI', 'Black-Asian', 'Black-HP', 'AI-Asian', 'AI-HP', 'Asian-HP', 'W-B-AI', 'W-B-A', 'W-B-HP', 'W-AI-A', 'W-AI-HP', 'W-A-HP', 'B-AI-A', 'W-B-AL-A', 'W-AI-A-HP', 'Other 3 race combo', 'Other 4 and 5 race combo')
levels(FS_Subset$'Citizenship_status') <- c('NATIVE, BORN IN THE UNITED STATES', 'NATIVE, BORN IN PUERTO RICO OR OTHER U.S. ISLAND AREAS', 'NATIVE, BORN ABROAD OF AMERICAN PARENT OR PARENTS', 'FOREIGN BORN, U.S. CITIZEN BY NATURALIZATION', 'FOREIGN BORN, NOT A CITIZEN OF THE UNITED STATES')
summary(FS_Subset$'Citizenship_status', title = "PRCITSHP")
table(FS_Subset$Ethnicity)
## Lets drop all levels that have less than 10 observations.
for(i in levels(FS_Subset$Ethnicity)) {
if(count(subset(FS_Subset, Ethnicity == i)) < 10){
print(i)
FS_Subset <- FS_Subset[!(FS_Subset$Ethnicity %in% c(i)), ]
}}
FS_Subset$Ethnicity <- droplevels(FS_Subset$Ethnicity)
table(FS_Subset$Ethnicity)
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(FS_Subset), replace = TRUE, prob = c(0.6, 0.4))
train <- FS_Subset[sample, ]
test  <- FS_Subset[!sample, ]
str(test)
str(train)
logistic <- glm(FS_Status ~ Ethnicity +  Family_Size + Household_Income:SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = train, family = "binomial")
logistic_model1.prob <- predict(logistic, test, type = "response")
logistic_model1.pred = rep("Food Secure", dim(test)[1])
logistic_model1.pred[logistic_model1.prob > .5] = "Food Insecure"
tb <- table(logistic_model1.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
train$logistic_model1_train.prob <- predict(logistic, train, type = "response")
# distribution of the prediction score grouped by known outcome
ggplot( train, aes( logistic_model1_train.prob, color = as.factor(FS_Status) ) ) +
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) +
scale_color_economist( name = "data", labels = c( "Food Secure", "Food Insecure" ) ) +
theme_economist()
test$logistic_model1.prob <- logistic_model1.prob
roc_model1 <- roc(FS_Status ~ logistic_model1.prob, data = test)
plot(roc_model1)
auc(roc_model1)
logistic_model_ncf.prob <- predict(logistic, test, type = "response")
logistic_model_ncf.pred = rep("Food Secure", dim(test)[1])
logistic_model_ncf.pred[logistic_model1.prob > .09] = "Food Insecure"
tb <- table(logistic_model_ncf.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
weight_minority_class = sum(FS_Subset$FS_Status == "Food Secure")/sum(FS_Subset$FS_Status == "Food Insecure")
for(i in seq_len(NROW(FS_Subset))){
if(FS_Subset$FS_Status[i] == "Food Insecure"){
FS_Subset$Weight[i] = weight_minority_class
}
else
FS_Subset$Weight[i] = 1
}
FS_Subset$Weight <- as.numeric(FS_Subset$Weight)
summary(FS_Subset$Weight)
## Splitting again because train and test doesn't contain the weight column
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(FS_Subset), replace = TRUE, prob = c(0.6, 0.4))
train <- FS_Subset[sample, ]
test  <- FS_Subset[!sample, ]
logistic_weighted <- glm(FS_Status ~ Ethnicity +  Family_Size + Household_Income:SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = train,  weights = Weight, family = "binomial")
logistic_model2.prob <- predict(logistic_weighted, test, type = "response")
logistic_model2.pred = rep("Food Secure", dim(test)[1])
logistic_model2.pred[logistic_model2.prob > .5] = "Food Insecure"
tb <- table(logistic_model2.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
test$logistic_model2.prob <- logistic_model2.prob
roc_model2 <- roc(FS_Status ~ logistic_model2.prob, data = test)
plot(roc_model2)
auc(roc_model2)
train$logistic_model2_train.prob <- predict(logistic_weighted, train, type = "response")
# distribution of the prediction score grouped by known outcome
ggplot( train, aes( logistic_model2_train.prob, color = as.factor(FS_Status) ) ) +
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) +
scale_color_economist( name = "data", labels = c( "Food Secure", "Food Insecure" ) ) +
theme_economist()
data.balanced.ou <- ovun.sample(FS_Status~., data=train, p=0.5,  seed=1, method="under")$data
logistic_both <- glm(FS_Status ~ Ethnicity + Family_Size + Household_Income:SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = data.balanced.ou,   family = "binomial")
logistic_model3.prob <- predict(logistic_both, test, type = "response")
logistic_model3.pred = rep("Food Secure", dim(test)[1])
logistic_model3.pred[logistic_model3.prob > .5] = "Food Insecure"
tb <- table(logistic_model3.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
train$logistic_model3_train.prob <- predict(logistic_both, train, type = "response")
ggplot( train, aes( logistic_model3_train.prob, color = as.factor(FS_Status) ) ) +
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) +
scale_color_economist( name = "data", labels = c( "Food Secure", "Food Insecure" ) ) +
theme_economist()
knn_data <- FS_Subset
knn_data$Family_Size <- as.numeric(FS_Subset$Family_Size)
knn_data$Household_Income <- as.numeric(FS_Subset$Household_Income)
knn_data$SNAP <- as.numeric(FS_Subset$SNAP)
knn_data$Number_of_Jobs <- as.numeric(FS_Subset$Number_of_Jobs)
knn_data$Hours_on_Jobs <- as.numeric(FS_Subset$Hours_on_Jobs)
knn_data$Number_of_children <- as.numeric(FS_Subset$Number_of_children)
knn_data$FS_Status <- as.numeric(FS_Subset$FS_Status)
num_data <- select_if(knn_data, is.numeric)
num_data <- as.data.frame(num_data[-c(8)])
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 1, 3)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 2, 1)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 3, 2)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 2, 0)
str(num_data)
data_balanced_under <- as.data.frame(ovun.sample(FS_Status ~ ., data = num_data, method = "both", N = nrow(num_data), seed = 1)$data)
table(data_balanced_under$FS_Status)
num_data <- data_balanced_under
str(num_data)
scaledata <- as.data.frame(scale(num_data, center = TRUE, scale = TRUE))
str(scaledata)
set.seed(1000)
knn_sample <- sample(2, nrow(scaledata), replace=TRUE, prob=c(0.67, 0.33))
# X variables
knn_training <- scaledata[knn_sample==1, 1:6]
knn_test <- scaledata[knn_sample==2, 1:6]
# Y variable
knn.trainLabels <- num_data[knn_sample==1, 7]
knn.testLabels <- num_data[knn_sample==2, 7]
# Loading package
library(e1071)
library(caTools)
library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
library(class)
# create an empty dataframe to store the results from confusion matrices
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
kseq <- seq(3,15,2)
for (kval in kseq)
{
print( paste("k = ", kval) )
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=kval)
knn_crosst <- CrossTable(knn.testLabels, knn_pred, prop.chisq = FALSE)
knn_crosst
#
cm = confusionMatrix(knn_pred, reference = as.factor(knn.testLabels )) # from caret library
# print.confusionMatrix(cm)
#
cmaccu = cm$overall['Accuracy']
#print( paste("Total Accuracy = ", cmaccu ) )
# print("Other metrics : ")
# print(cm$byClass)
#
cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics
# cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
ResultDf = rbind(ResultDf, cmt)
print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
ResultDf = rbind(ResultDf, cmt)
xkabledply(ResultDf, "Total Accuracy Summary")
ggplot(ResultDf,aes(x = k, y = Total.Accuracy)) +
geom_line(color = "maroon", size = 1.5) +
geom_point(size = 3) +
labs(title = "Accuracy vs k")
library(dplyr)
library(ezids)
library(ggplot2)
library(epiR)
library(pROC)
library(smotefamily)
library(ROSE)
library(ggthemes)
library(caret)
library(car)
library(ROSE)
Food_Sec <- data.frame(read.csv("dec21pub.csv"))
FS_Subset <- subset(Food_Sec, HRINTSTA == 001 & HRSUPINT == 001 & HRFS12MD != -9)
FS_Subset <- subset(FS_Subset, select = c(	"GESTFIPS",	"HRNUMHOU",	"HEFAMINC",	"HESP1",	"PTDTRACE",	"PRCITSHP",	"PEMJNUM",	"PEHRUSL1",	"PEEDUCA", "PRNMCHLD" , "HRFS12MD"))
FS_Subset <- FS_Subset %>% rename("States" = "GESTFIPS", "Family_Size" = "HRNUMHOU",	"Household_Income" = "HEFAMINC",	"SNAP" = "HESP1",	"Ethnicity" =	"PTDTRACE", "Citizenship_status" = "PRCITSHP",	"Number_of_Jobs" = "PEMJNUM",	"Hours_on_Jobs" = "PEHRUSL1" , "Education_Level" = "PEEDUCA" , "Number_of_children" = "PRNMCHLD",  "FoodSecurity_score" = "HRFS12MD")
## Converting the all the columns to factors as they are all ordinal(except the Id, but since it's categorical i'm converting it into a factor too)
FS_Subset[] <- lapply( FS_Subset, factor)
str(FS_Subset)
levels(FS_Subset$'FoodSecurity_score') <- c( "High Food Security", "Marginal Food Security", "Low Food Security", "Very Low Food Security")
FS_Subset$FS_Status <- FS_Subset$FoodSecurity_score
levels(FS_Subset$FS_Status) <- c( "Food Secure", "Food Secure", "Food Insecure", "Food Insecure")
levels(FS_Subset$'Ethnicity') <- c('White only', 'Black only', 'American Indian, Alaskan native only', 'Asian Only', 'Hawaiian', 'White-black', 'White-AI', 'White-Asian', 'White-HP', 'Black-AI', 'Black-Asian', 'Black-HP', 'AI-Asian', 'AI-HP', 'Asian-HP', 'W-B-AI', 'W-B-A', 'W-B-HP', 'W-AI-A', 'W-AI-HP', 'W-A-HP', 'B-AI-A', 'W-B-AL-A', 'W-AI-A-HP', 'Other 3 race combo', 'Other 4 and 5 race combo')
levels(FS_Subset$'Citizenship_status') <- c('NATIVE, BORN IN THE UNITED STATES', 'NATIVE, BORN IN PUERTO RICO OR OTHER U.S. ISLAND AREAS', 'NATIVE, BORN ABROAD OF AMERICAN PARENT OR PARENTS', 'FOREIGN BORN, U.S. CITIZEN BY NATURALIZATION', 'FOREIGN BORN, NOT A CITIZEN OF THE UNITED STATES')
summary(FS_Subset$'Citizenship_status', title = "PRCITSHP")
table(FS_Subset$Ethnicity)
## Lets drop all levels that have less than 10 observations.
for(i in levels(FS_Subset$Ethnicity)) {
if(count(subset(FS_Subset, Ethnicity == i)) < 10){
print(i)
FS_Subset <- FS_Subset[!(FS_Subset$Ethnicity %in% c(i)), ]
}}
FS_Subset$Ethnicity <- droplevels(FS_Subset$Ethnicity)
table(FS_Subset$Ethnicity)
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(FS_Subset), replace = TRUE, prob = c(0.6, 0.4))
train <- FS_Subset[sample, ]
test  <- FS_Subset[!sample, ]
str(test)
str(train)
logistic <- glm(FS_Status ~ Ethnicity +  Family_Size + Household_Income:SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = train, family = "binomial")
logistic_model1.prob <- predict(logistic, test, type = "response")
logistic_model1.pred = rep("Food Secure", dim(test)[1])
logistic_model1.pred[logistic_model1.prob > .5] = "Food Insecure"
tb <- table(logistic_model1.pred, test$FS_Status)
tb[1:2,2:1]
precision <- round(precision(tb[1:2,2:1])*100,2)
recall <- round(recall(tb[1:2,2:1])*100,1)
lg_model_graph <- data.frame(precision , recall )
p <- barplot(as.matrix(lg_model_graph),beside=TRUE, col=rgb(0.2,0.3,0.6,0.6), space = c(0.1, 0.1))
text(x = p, y = lg_model_graph -  2, labels = lg_model_graph)
train$logistic_model1_train.prob <- predict(logistic, train, type = "response")
# distribution of the prediction score grouped by known outcome
ggplot( train, aes( logistic_model1_train.prob, color = as.factor(FS_Status) ) ) +
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) +
scale_color_economist( name = "data", labels = c( "Food Secure", "Food Insecure" ) ) +
theme_economist()
knn_data <- FS_Subset
knn_data$Family_Size <- as.numeric(FS_Subset$Family_Size)
knn_data$Household_Income <- as.numeric(FS_Subset$Household_Income)
knn_data$SNAP <- as.numeric(FS_Subset$SNAP)
knn_data$Number_of_Jobs <- as.numeric(FS_Subset$Number_of_Jobs)
knn_data$Hours_on_Jobs <- as.numeric(FS_Subset$Hours_on_Jobs)
knn_data$Number_of_children <- as.numeric(FS_Subset$Number_of_children)
knn_data$FS_Status <- as.numeric(FS_Subset$FS_Status)
num_data <- select_if(knn_data, is.numeric)
num_data <- as.data.frame(num_data[-c(8)])
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 1, 3)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 2, 1)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 3, 2)
num_data$FS_Status <- replace(num_data$FS_Status, num_data$FS_Status == 2, 0)
str(num_data)
data_balanced_under <- as.data.frame(ovun.sample(FS_Status ~ ., data = num_data, method = "both", N = nrow(num_data), seed = 1)$data)
table(data_balanced_under$FS_Status)
data_balanced_under <- as.data.frame(ovun.sample(FS_Status ~ ., data = num_data, method = "both", N = nrow(num_data), seed = 1)$data)
table(data_balanced_under$FS_Status)
data_balanced_under <- as.data.frame(ovun.sample(FS_Status ~ ., data = num_data, method = "both", N = nrow(num_data), seed = 1)$data)
table(data_balanced_under$FS_Status)
data_balanced_under <- as.data.frame(ovun.sample(FS_Status ~ ., data = num_data, method = "both", N = nrow(num_data), seed = 1)$data)
table(data_balanced_under$FS_Status)
num_data <- data_balanced_under
str(num_data)
scaledata <- as.data.frame(scale(num_data, center = TRUE, scale = TRUE))
str(scaledata)
set.seed(1000)
knn_sample <- sample(2, nrow(scaledata), replace=TRUE, prob=c(0.67, 0.33))
# X variables
knn_training <- scaledata[knn_sample==1, 1:6]
knn_test <- scaledata[knn_sample==2, 1:6]
# Y variable
knn.trainLabels <- num_data[knn_sample==1, 7]
knn.testLabels <- num_data[knn_sample==2, 7]
# Loading package
library(e1071)
library(caTools)
library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
library(class)
# create an empty dataframe to store the results from confusion matrices
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
kseq <- seq(3,15,2)
for (kval in kseq)
{
print( paste("k = ", kval) )
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=kval)
knn_crosst <- CrossTable(knn.testLabels, knn_pred, prop.chisq = FALSE)
knn_crosst
#
cm = confusionMatrix(knn_pred, reference = as.factor(knn.testLabels )) # from caret library
# print.confusionMatrix(cm)
#
cmaccu = cm$overall['Accuracy']
#print( paste("Total Accuracy = ", cmaccu ) )
# print("Other metrics : ")
# print(cm$byClass)
#
cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics
# cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
ResultDf = rbind(ResultDf, cmt)
print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
ResultDf = rbind(ResultDf, cmt)
xkabledply(ResultDf, "Total Accuracy Summary")
ggplot(ResultDf,aes(x = k, y = Total.Accuracy)) +
geom_line(color = "maroon", size = 1.5) +
geom_point(size = 3) +
labs(title = "Accuracy vs k")
library(class)
knn_pred <- knn(train = knn_training, test = knn_test, cl=knn.trainLabels, k=15)
knn_crosst <- gmodels::CrossTable(x = knn.testLabels, y = knn_pred, prop.chisq = FALSE)
xkabledply(data.frame(cm$byClass), title=paste("k = ",6))
